{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code is for ModelA\n",
    "build model  for each target country without transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T02:05:56.639645Z",
     "start_time": "2020-06-23T02:05:53.225196Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "import tensorflow as tf\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import datetime \n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, Dense,  Lambda\n",
    "\n",
    "from keras.backend import slice\n",
    "from keras.constraints import max_norm\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='-1'\n",
    "\n",
    "##ã€€locate the directory storing the data \n",
    "os.chdir(os.getcwd()+'/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T02:05:56.645317Z",
     "start_time": "2020-06-23T02:05:56.642241Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T02:05:56.655354Z",
     "start_time": "2020-06-23T02:05:56.649280Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_sequences_x(data, seq_length):\n",
    "    xs = []\n",
    "    for i in range(len(data)-seq_length+1):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        xs.append(x)\n",
    "    return np.array(xs)\n",
    "\n",
    "def create_sequences_y(data, seq_length):\n",
    "    ys = []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        y = data[i]\n",
    "        ys.append(y)\n",
    "    return np.array(ys)\n",
    "\n",
    "def MAPE(y, y_pred):\n",
    "    mape = sum(abs(y-y_pred)/y)/len(y)\n",
    "    print('MAPE: ', mape)\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T02:49:42.788390Z",
     "start_time": "2020-06-23T02:49:42.771889Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from re import sub\n",
    "mypath = 'target/'\n",
    "target_countries = ['Albania','Algeria','Argentina','Armenia','Australia','Azerbaijan','Bangladesh','Belarus','Belgium','Bermuda',\n",
    "             'Bolivia','Brazil','Bulgaria','Canada','Chile','Colombia','Costa Rica','Cuba','Czech Republic','Denmark',\n",
    "             'El Salvador','Estonia','Finland','France','Ghana','Gibraltar','Greece','Honduras','Hungary','India',\n",
    "             'Indonesia','Iran','Iraq','Ireland','Israel','Jamaica','Jordan','Liberia','Luxembourg','Malaysia','Mexico',\n",
    "             'Morocco','Nepal','Netherlands','Nigeria','Pakistan','Paraguay','Peru','Philippines','Poland','Portugal',\n",
    "             'Qatar','Republic of the Congo','Romania','Russia','Rwanda','Saudi Arabia','Senegal','Sierra Leone',\n",
    "             'Singapore','Slovakia','Slovenia','South Africa','Sri Lanka','Switzerland','Thailand','Tunisia','Turkey',\n",
    "             'Ukraine','United Kingdom','United States','Venezuela']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T02:06:21.092993Z",
     "start_time": "2020-06-23T02:06:21.077148Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ret_test = pd.DataFrame(index=target_countries, columns=['MAPE'])\n",
    "no_transfer = pd.DataFrame(index=['loop1','loop2','loop3','loop4','loop5'], columns=['MAPE(mean)','MAPE(std)','MAPE<0.1','MAPE<0.05'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T02:07:34.501573Z",
     "start_time": "2020-06-23T02:06:28.508375Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iraq\n",
      "WARNING:tensorflow:From /data/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4139: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "MAPE:  0.16406849036341117\n",
      "Denmark\n",
      "MAPE:  0.07906652391111721\n",
      "Republic of the Congo\n",
      "MAPE:  0.055073642685664344\n",
      "Slovakia\n",
      "MAPE:  0.10690454559196794\n",
      "Azerbaijan\n",
      "MAPE:  0.13670252844080277\n",
      "Australia\n",
      "MAPE:  0.11975307503726358\n",
      "Bolivia\n",
      "MAPE:  0.25038537400190836\n",
      "Bangladesh\n",
      "MAPE:  0.1866943486987426\n",
      "Indonesia\n",
      "MAPE:  0.09242162727289838\n",
      "Estonia\n",
      "MAPE:  0.09535000168779455\n"
     ]
    }
   ],
   "source": [
    "pred_length = 7\n",
    "seq_length = 7\n",
    "dict_res = {}\n",
    "for l in range(5):\n",
    "    for tar in target_countries:\n",
    "        print(tar)\n",
    "        # data preprocessing\n",
    "        df = pd.read_excel('target/'+tar+'.xlsx', index_col=0)\n",
    "\n",
    "        df_new_1day = df.diff(periods=1)\n",
    "        df_new_1day.rename(columns={'confirmed cases per million':'new cases'}, inplace=True)\n",
    "\n",
    "        df_new_7days = df[['confirmed cases per million']].diff(periods=pred_length)\n",
    "        df_new_7days.rename(columns={'confirmed cases per million':'new cases'}, inplace=True)\n",
    "        df_new_7days['cum cases'] = 0\n",
    "        df_new_7days['cum cases'][pred_length:] = df['confirmed cases per million'].values[0:len(df_new_7days)-pred_length]\n",
    "\n",
    "        x_seq0 = create_sequences_x(df_new_1day.dropna().to_numpy(), seq_length)\n",
    "        y_seq0 = create_sequences_y(df_new_7days.dropna().to_numpy(), seq_length)\n",
    "        x_seq0 = x_seq0[0:len(y_seq0)]\n",
    "        x_seq1 = np.reshape(x_seq0, newshape=(-1,1))\n",
    "        scaler_x = MinMaxScaler()\n",
    "        scaler_y = MinMaxScaler()\n",
    "\n",
    "        scaler_x = scaler_x.fit(x_seq1)\n",
    "        x = scaler_x.transform(x_seq1)\n",
    "        x = np.reshape(x, newshape=(x_seq0.shape))\n",
    "        y_seq1 = np.reshape(y_seq0[:,0:1], newshape=(-1,1))\n",
    "        scaler_y = scaler_y.fit(y_seq1)\n",
    "        y = scaler_y.transform(y_seq1)\n",
    "        y = np.reshape(y, newshape=(y_seq0[:,0:1].shape))\n",
    "\n",
    "        test_idx = int(len(x)*0.8)\n",
    "\n",
    "        X_train = x[0:test_idx, :, 0:1].copy()\n",
    "        y_train = np.reshape(y[0:test_idx], (-1))\n",
    "        X_test = x[test_idx:,:,0:1].copy()\n",
    "        y_test = np.reshape(y[test_idx:], (-1))\n",
    "\n",
    "        # Building the RNN\n",
    "        main_input = Input(shape=(seq_length,1,), dtype='float32', name='main_input')  \n",
    "        lstm_out = LSTM(16,activation='relu')(main_input)    \n",
    "        main_output = Dense(units = 1,activation='sigmoid')(lstm_out)\n",
    "        regressor = Model(inputs=main_input, outputs=main_output)\n",
    "\n",
    "        regressor.compile(optimizer='adam', loss='mse')\n",
    "        # Fitting the RNN to the Training set\n",
    "        regressor.fit(X_train, y_train, epochs = 7, batch_size = 1, verbose=0)\n",
    "\n",
    "        # Predicting daily cases\n",
    "        predicted_cases = regressor.predict(X_test)\n",
    "        predicted_cases = scaler_y.inverse_transform(predicted_cases)\n",
    "\n",
    "        true_cases = np.reshape(scaler_y.inverse_transform(np.reshape(y_test,(-1,1))),(-1))+y_seq0[test_idx:,1]\n",
    "        predicted_cases = np.reshape(predicted_cases,(-1))+y_seq0[test_idx:,1]\n",
    "        mape = MAPE(true_cases, predicted_cases)\n",
    "\n",
    "        ret_test.loc[tar, 'MAPE'] = mape\n",
    "    no_transfer.loc['loop'+str(l+1), 'MAPE(mean)'] = ret_test.MAPE.mean() \n",
    "    no_transfer.loc['loop'+str(l+1), 'MAPE(std)'] = ret_test.MAPE.std()\n",
    "    no_transfer.loc['loop'+str(l+1), 'MAPE<0.1'] = ret_test[(ret_test.MAPE<0.1)].shape[0]\n",
    "    no_transfer.loc['loop'+str(l+1), 'MAPE<0.05']=ret_test[(ret_test.MAPE<0.05)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:21:02.235534Z",
     "start_time": "2020-06-19T08:21:02.205199Z"
    }
   },
   "outputs": [],
   "source": [
    "no_transfer.to_csv('../result/modelA_notransfer.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
