{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code is for ModelB\n",
    "build source model based on source countries data(CCPM only) and predict CCPM for target countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T02:24:50.881212Z",
     "start_time": "2020-06-23T02:24:47.408918Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import datetime \n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.models import load_model,clone_model\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, Dense,  Lambda\n",
    "\n",
    "from keras.backend import slice\n",
    "from keras.constraints import max_norm\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='-1'\n",
    "\n",
    "##　locate the directory storing the data \n",
    "os.chdir(os.getcwd()+'/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T02:24:50.887610Z",
     "start_time": "2020-06-23T02:24:50.884112Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T02:24:50.897005Z",
     "start_time": "2020-06-23T02:24:50.890435Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_sequences_x(data, seq_length):\n",
    "    xs = []\n",
    "    for i in range(len(data)-seq_length+1):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        xs.append(x)\n",
    "\n",
    "    return np.array(xs)\n",
    "\n",
    "\n",
    "def create_sequences_y(data, seq_length):\n",
    "    ys = []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        y = data[i]\n",
    "        ys.append(y)\n",
    "    return np.array(ys)\n",
    "\n",
    "def MAPE(y, y_pred):\n",
    "    mape = sum(abs(y-y_pred)/y)/len(y)\n",
    "    print('MAPE: ', mape)\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build the source model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Construct source  sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T02:19:04.051857Z",
     "start_time": "2020-06-23T02:19:04.045085Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from re import sub\n",
    "mypath = 'source/'\n",
    "source_countries=['Austria','China (except Hubei)','Croatia','Germany','Hubei','Italy','Japan',\n",
    "            'Lebanon','Monaco','Norway','Oman','United Arab Emirates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:29:30.158441Z",
     "start_time": "2020-06-19T08:29:29.809291Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Croatia\n",
      "Norway\n",
      "Lebanon\n",
      "Hubei\n",
      "Austria\n",
      "China (except Hubei)\n",
      "Oman\n",
      "United Arab Emirates\n",
      "Japan\n",
      "Germany\n",
      "Italy\n",
      "Monaco\n"
     ]
    }
   ],
   "source": [
    "pred_length = 7\n",
    "seq_length = 7\n",
    "x_seq0 = []\n",
    "y_seq0 = []\n",
    "\n",
    "for sc in source_countries:\n",
    "    print(sc)\n",
    "    # data preprocessing\n",
    "    df = pd.read_excel('source/'+sc+'.xlsx', index_col=0)\n",
    "\n",
    "    df_new_1day = df[['confirmed cases per million']].diff(periods=1)\n",
    "    df_new_1day.rename(columns={'confirmed cases per million':'new cases'}, inplace=True)\n",
    "\n",
    "    df_new_7days = df[['confirmed cases per million']].diff(periods=pred_length)\n",
    "    df_new_7days.rename(columns={'confirmed cases per million':'new cases'}, inplace=True)\n",
    "\n",
    "    df_new_7days['cum cases'] = 0\n",
    "    df_new_7days['cum cases'][pred_length:] = df['confirmed cases per million'].values[0:len(df_new_7days)-pred_length]\n",
    "    \n",
    "    scaler_x = MinMaxScaler() #scale data into 0-1\n",
    "    scaler_y = MinMaxScaler()\n",
    "\n",
    "    if len(x_seq0)==0:\n",
    "        x_seq0 = create_sequences_x(df_new_1day.dropna().to_numpy(), seq_length)\n",
    "        y_seq0 = create_sequences_y(df_new_7days.dropna().to_numpy(), seq_length)\n",
    "        x_seq0 = x_seq0[0:len(y_seq0)]\n",
    "    else:\n",
    "        tx_seq0 = create_sequences_x(df_new_1day.dropna().to_numpy(), seq_length)\n",
    "        ty_seq0 = create_sequences_y(df_new_7days.dropna().to_numpy(), seq_length)\n",
    "        tx_seq0 = tx_seq0[0:len(ty_seq0)]\n",
    "        \n",
    "        x_seq0 = np.concatenate((x_seq0, tx_seq0),axis=0)\n",
    "        y_seq0 = np.concatenate((y_seq0, ty_seq0),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 scale the sequence values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:29:34.083712Z",
     "start_time": "2020-06-19T08:29:34.076824Z"
    }
   },
   "outputs": [],
   "source": [
    "x_seq1 = np.reshape(x_seq0, newshape=(-1,1))\n",
    "\n",
    "scaler_x = scaler_x.fit(x_seq1)\n",
    "x = scaler_x.transform(x_seq1)\n",
    "x = np.reshape(x, newshape=(x_seq0.shape))\n",
    "y_seq1 = np.reshape(y_seq0[:,0:1], newshape=(-1,1))\n",
    "\n",
    "scaler_y = scaler_y.fit(y_seq1)\n",
    "y = scaler_y.transform(y_seq1)\n",
    "\n",
    "y = np.reshape(y, newshape=(y_seq0[:,0:1].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.3 source model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T05:14:29.306788Z",
     "start_time": "2020-06-18T05:14:23.307052Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4139: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "Epoch 1/8\n",
      "714/714 [==============================] - 1s 2ms/step - loss: 0.0219\n",
      "Epoch 2/8\n",
      "714/714 [==============================] - 0s 553us/step - loss: 0.0186\n",
      "Epoch 3/8\n",
      "714/714 [==============================] - 0s 624us/step - loss: 0.0171\n",
      "Epoch 4/8\n",
      "714/714 [==============================] - 0s 583us/step - loss: 0.0157\n",
      "Epoch 5/8\n",
      "714/714 [==============================] - 0s 540us/step - loss: 0.0146\n",
      "Epoch 6/8\n",
      "714/714 [==============================] - 0s 573us/step - loss: 0.0137\n",
      "Epoch 7/8\n",
      "714/714 [==============================] - 0s 585us/step - loss: 0.0131\n",
      "Epoch 8/8\n",
      "714/714 [==============================] - 0s 501us/step - loss: 0.0127\n",
      "MAPE:  1.6715718050490873\n",
      "MAPE:  168.68416785978138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "168.68416785978138"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed(123)\n",
    "train_idx = sample(range(len(x)),int(len(x)*0.8))\n",
    "test_idx = set(range(len(x))).difference(train_idx)\n",
    "\n",
    "\n",
    "X_train = x[train_idx].copy()\n",
    "y_train = np.reshape(y[train_idx], (-1))\n",
    "\n",
    "X_test = x[list(test_idx)].copy()\n",
    "y_test = np.reshape(y[list(test_idx)], (-1))\n",
    "\n",
    "# Building the RNN\n",
    "\n",
    "main_input = Input(shape=(seq_length,1,), dtype='float32', name='main_input')  \n",
    "\n",
    "lstm_out = LSTM(4)(main_input)  \n",
    "main_output = Dense(units = 1)(lstm_out)\n",
    "regressor = Model(inputs=main_input, outputs=main_output)\n",
    "\n",
    "regressor.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = 9, batch_size = 16)#  10\n",
    "regressor.save('../model/ModelB_nocontrol.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Target countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T02:25:47.224606Z",
     "start_time": "2020-06-23T02:25:47.215619Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from re import sub\n",
    "mypath = 'target/'\n",
    "target_countries = ['Albania','Algeria','Argentina','Armenia','Australia','Azerbaijan','Bangladesh','Belarus','Belgium','Bermuda',\n",
    "             'Bolivia','Brazil','Bulgaria','Canada','Chile','Colombia','Costa Rica','Cuba','Czech Republic','Denmark',\n",
    "             'El Salvador','Estonia','Finland','France','Ghana','Gibraltar','Greece','Honduras','Hungary','India',\n",
    "             'Indonesia','Iran','Iraq','Ireland','Israel','Jamaica','Jordan','Liberia','Luxembourg','Malaysia','Mexico',\n",
    "             'Morocco','Nepal','Netherlands','Nigeria','Pakistan','Paraguay','Peru','Philippines','Poland','Portugal',\n",
    "             'Qatar','Republic of the Congo','Romania','Russia','Rwanda','Saudi Arabia','Senegal','Sierra Leone',\n",
    "             'Singapore','Slovakia','Slovenia','South Africa','Sri Lanka','Switzerland','Thailand','Tunisia','Turkey',\n",
    "             'Ukraine','United Kingdom','United States','Venezuela']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T02:25:48.891009Z",
     "start_time": "2020-06-23T02:25:48.872219Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_model = load_model('../model/ModelB_nocontrol.pkl')\n",
    "ret_test = pd.DataFrame(index=target_countries, columns=['MAPE'])\n",
    "no_control = pd.DataFrame(index=['loop1','loop2','loop3','loop4','loop5'], columns=['MAPE(mean)','MAPE(std)','MAPE<0.1','MAPE<0.05'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:41:29.706622Z",
     "start_time": "2020-06-19T08:30:03.589473Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iraq\n",
      "MAPE:  0.1170193641803412\n",
      "Denmark\n",
      "MAPE:  0.04168017167168084\n",
      "Republic of the Congo\n",
      "MAPE:  0.31168769466453444\n",
      "Slovakia\n",
      "MAPE:  0.05124198961274342\n",
      "Azerbaijan\n",
      "MAPE:  0.08034460629248753\n",
      "Australia\n",
      "MAPE:  0.050189969084553004\n",
      "Bolivia\n",
      "MAPE:  0.19044346513275776\n",
      "Bangladesh\n",
      "MAPE:  0.09404682224713405\n",
      "Indonesia\n",
      "MAPE:  0.03467051292532779\n",
      "Estonia\n",
      "MAPE:  0.04035225086349593\n",
      "Rwanda\n",
      "MAPE:  0.1097237846244324\n",
      "Nigeria\n",
      "MAPE:  0.2004347865380084\n",
      "Bermuda\n",
      "MAPE:  0.03000449197744275\n",
      "Jordan\n",
      "MAPE:  0.039047787775498714\n",
      "Argentina\n",
      "MAPE:  0.16509828663195478\n",
      "Finland\n",
      "MAPE:  0.04418868529768805\n",
      "Paraguay\n",
      "MAPE:  0.0704873283773625\n",
      "Saudi Arabia\n",
      "MAPE:  0.06720963706623531\n",
      "Turkey\n",
      "MAPE:  0.04355456795483205\n",
      "Ireland\n",
      "MAPE:  0.03349578921839156\n",
      "Iran\n",
      "MAPE:  0.017478653125681927\n",
      "Switzerland\n",
      "MAPE:  0.042427358132972326\n",
      "Colombia\n",
      "MAPE:  0.11363012543007756\n",
      "Albania\n",
      "MAPE:  0.02317180880707509\n",
      "Pakistan\n",
      "MAPE:  0.08181637016683428\n",
      "Belgium\n",
      "MAPE:  0.026522221387351403\n",
      "United States\n",
      "MAPE:  0.008611427075104686\n",
      "Israel\n",
      "MAPE:  0.050948619065063316\n",
      "Liberia\n",
      "MAPE:  0.13753663441265218\n",
      "Philippines\n",
      "MAPE:  0.02598005901886039\n",
      "Morocco\n",
      "MAPE:  0.04312943089271286\n",
      "Nepal\n",
      "MAPE:  0.6215780435060321\n",
      "Ghana\n",
      "MAPE:  0.046041590919065706\n",
      "Poland\n",
      "MAPE:  0.010571337133618968\n",
      "Mexico\n",
      "MAPE:  0.1124452862144875\n",
      "Tunisia\n",
      "MAPE:  0.055411429633725376\n",
      "Peru\n",
      "MAPE:  0.08597353121993075\n",
      "Belarus\n",
      "MAPE:  0.03478777115177078\n",
      "Czech Republic\n",
      "MAPE:  0.03191424025845781\n",
      "Gibraltar\n",
      "MAPE:  0.023504129930848265\n",
      "Brazil\n",
      "MAPE:  0.14438233153616398\n",
      "Qatar\n",
      "MAPE:  0.15670688041745\n",
      "South Africa\n",
      "MAPE:  0.15751682340437467\n",
      "Cuba\n",
      "MAPE:  0.05255902689495461\n",
      "Jamaica\n",
      "MAPE:  0.0358416367869266\n",
      "Bulgaria\n",
      "MAPE:  0.029316380231651312\n",
      "Honduras\n",
      "MAPE:  0.15021987616464008\n",
      "Netherlands\n",
      "MAPE:  0.046813797802802704\n",
      "Sierra Leone\n",
      "MAPE:  0.04801005368504795\n",
      "Armenia\n",
      "MAPE:  0.14109152479992537\n",
      "Venezuela\n",
      "MAPE:  0.23499616307443122\n",
      "Slovenia\n",
      "MAPE:  0.049534900996253066\n",
      "India\n",
      "MAPE:  0.07556047632817392\n",
      "Malaysia\n",
      "MAPE:  0.02907040194930228\n",
      "Ukraine\n",
      "MAPE:  0.012517914183749063\n",
      "Portugal\n",
      "MAPE:  0.029835974108273287\n",
      "Thailand\n",
      "MAPE:  0.06413090221187139\n",
      "Hungary\n",
      "MAPE:  0.03338326881034962\n",
      "Luxembourg\n",
      "MAPE:  0.023533362565367717\n",
      "Sri Lanka\n",
      "MAPE:  0.08553101242392988\n",
      "Russia\n",
      "MAPE:  0.0190097727330329\n",
      "France\n",
      "MAPE:  0.0423954187739227\n",
      "Romania\n",
      "MAPE:  0.03437492707693759\n",
      "Singapore\n",
      "MAPE:  0.0327453343578303\n",
      "Algeria\n",
      "MAPE:  0.02302832170525638\n",
      "Georgia\n",
      "MAPE:  0.03152943571663317\n",
      "Costa Rica\n",
      "MAPE:  0.014096430741192848\n",
      "Greece\n",
      "MAPE:  0.04107729902567435\n",
      "Canada\n",
      "MAPE:  0.017002624784858276\n",
      "United Kingdom\n",
      "MAPE:  0.028146271119882382\n",
      "Chile\n",
      "MAPE:  0.1794123808130522\n",
      "El Salvador\n",
      "MAPE:  0.09088900462599049\n",
      "Senegal\n",
      "MAPE:  0.0369660762447818\n"
     ]
    }
   ],
   "source": [
    "for l in range(5):\n",
    "    for tar in target_countries:\n",
    "        print(tar)\n",
    "        # data preprocessing\n",
    "\n",
    "        ## scale data\n",
    "        df = pd.read_excel('target/'+tar+'.xlsx', index_col=0)\n",
    "\n",
    "        df_new_1day = df.diff(periods=1)\n",
    "        df_new_1day.rename(columns={'confirmed cases per million':'new cases'}, inplace=True)\n",
    "\n",
    "        df_new_7days = df[['confirmed cases per million']].diff(periods=pred_length)\n",
    "        df_new_7days.rename(columns={'confirmed cases per million':'new cases'}, inplace=True)\n",
    "\n",
    "        df_new_7days['cum cases'] = 0\n",
    "        df_new_7days['cum cases'][pred_length:] = df['confirmed cases per million'].values[0:len(df_new_7days)-pred_length]\n",
    "\n",
    "        x_seq0 = create_sequences_x(df_new_1day.dropna().to_numpy(), seq_length)\n",
    "        y_seq0 = create_sequences_y(df_new_7days.dropna().to_numpy(), seq_length)\n",
    "        x_seq0 = x_seq0[0:len(y_seq0)]\n",
    "        x_seq1 = np.reshape(x_seq0, newshape=(-1,1))\n",
    "\n",
    "        x = scaler_x.transform(x_seq1)\n",
    "\n",
    "        x = np.reshape(x, newshape=(x_seq0.shape))\n",
    "        y_seq1 = np.reshape(y_seq0[:,0:1], newshape=(-1,1))\n",
    "        y = scaler_y.transform(y_seq1)\n",
    "\n",
    "        y = np.reshape(y, newshape=(y_seq0[:,0:1].shape))\n",
    "        model =clone_model(pred_model)\n",
    "        model.set_weights(pred_model.get_weights())\n",
    "        test_idx = int(len(x)*0.8)\n",
    "\n",
    "        X_train = x[0:test_idx, :, 0:1].copy()\n",
    "        y_train = np.reshape(y[0:test_idx], (-1))\n",
    "\n",
    "        X_test = x[test_idx:,:,0:1].copy()\n",
    "        y_test = np.reshape(y[test_idx:], (-1))\n",
    "\n",
    "\n",
    "        for layer in model.layers[:-1]:\n",
    "            layer.trainable=False\n",
    "        for layer in model.layers[-1:]:\n",
    "            layer.trainable=True\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        # Fitting the RNN to the Training set\n",
    "        model.fit(X_train, y_train, epochs = 7, batch_size = 4, verbose=0)# 原来10\n",
    "\n",
    "        # Predicting daily cases\n",
    "        predicted_cases = model.predict(X_test)\n",
    "        predicted_cases = scaler_y.inverse_transform(predicted_cases)\n",
    "\n",
    "        true_cases = np.reshape(scaler_y.inverse_transform(np.reshape(y_test,(-1,1))),(-1))+y_seq0[test_idx:,1]\n",
    "        predicted_cases = np.reshape(predicted_cases,(-1))+y_seq0[test_idx:,1]\n",
    "\n",
    "\n",
    "        mape = MAPE(true_cases, predicted_cases)\n",
    "        ret_test.loc[tar, 'MAPE'] = mape\n",
    "        \n",
    "    no_control.loc['loop'+str(l+1), 'MAPE(mean)'] = ret_test.MAPE.mean() \n",
    "    no_control.loc['loop'+str(l+1), 'MAPE(std)'] = ret_test.MAPE.std()\n",
    "    no_control.loc['loop'+str(l+1), 'MAPE<0.1'] = ret_test[(ret_test.MAPE<0.1)].shape[0]\n",
    "    no_control.loc['loop'+str(l+1), 'MAPE<0.05']=ret_test[(ret_test.MAPE<0.05)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:42:31.968943Z",
     "start_time": "2020-06-19T08:42:31.952780Z"
    }
   },
   "outputs": [],
   "source": [
    "no_control.to_csv('../result/ModelB_nocontrol.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
